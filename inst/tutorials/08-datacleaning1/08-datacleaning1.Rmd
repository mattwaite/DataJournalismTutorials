---
title: "Data Journalism Lesson 8: Data Cleaning 1: Data Smells"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
description: >
  Stop a wrong story before it starts.
---

```{r setup, include=FALSE}
library(learnr)
library(gradethis)
library(tidyverse)
library(glue)
library(lubridate)
knitr::opts_chunk$set(echo = FALSE)
tutorial_options(exercise.completion=FALSE)
```

# Data Cleaning Part I: Data smells

## The Basics

Any time you are given a dataset from anyone, you should immediately be suspicious. Is this data what I think it is? Does it include what I expect? Is there anything I need to know about it? Will it produce the information I expect?

One of the first things you should do is give it the smell test.

Failure to give data the smell test [can lead you to miss stories and get your butt kicked on a competitive story](https://source.opennews.org/en-US/learning/handling-data-about-race-and-ethnicity/).

Let's look at our campus crime data again.

With data analysis, often a first step is called Exploratory Data Analysis or EDA. EDA has been around for a long time -- John Tukey started pushing the idea in 1970 and wrote the text that would lay the groundwork for generations of data analysts in 1977 (I have a copy in my office!). But EDA treats data in an almost neutral way - it's almost naive. Data smells treats data with skepticism and distrust. With data smells, we're trying to find common mistakes in data because we have to know if they are there. [For more on data smells, read the GitHub wiki post that started it all](https://github.com/nikeiubel/data-smells/wiki/Ensuring-Accuracy-in-Data-Journalism). The common mistakes we're looking for are:

-   Missing data
-   Gaps in data
-   Wrong type of data
-   Outliers
-   Sharp curves
-   Conflicting information within a dataset
-   Conflicting information across datasets
-   Wrongly derived data
-   Internal inconsistency
-   External inconsistency
-   Wrong spatial data
-   Unusable data, including non-standard abbreviations, ambiguous data, extraneous data, inconsistent data

Not all of these data smells are detectable in code. You may have to ask people about the data. You may have to compare it to another dataset yourself. Does the agency that uses the data produce reports from the data? Does your analysis match those reports? That will expose wrongly derived data, or wrong units, or mistakes you made with inclusion or exclusion.

But with several of these data smells, we can do them first, before we do anything else.

Let's work on some examples using the UNLPD reports data. You can download the data here if you want to use it in your own notebook -- and this is the same data we've used before, so if you already downloaded it, you don't need to do it again. **For purposes of this exercise, you don't need to do this. The data is included here if you want to try this in your own notebook.**

```{r echo=FALSE, class.output="bg-info", results="asis",  message=FALSE,  warning=FALSE}
library(downloadthis)
library(glue)

dllink <- download_link(
  link = "http://mattwaite.github.io/datajournalismfiles/crimelogs.csv",
  button_label = "Download csv file",
  button_type = "danger",
  has_icon = TRUE,
  icon = "fa fa-save",
  self_contained = FALSE
)

glue("<pre><p><strong>For this walkthrough:</strong></p><p>{dllink}</p></pre>")
```

First we'll need the tidyverse and lubridate. Your first step is always loading libraries and you'll need to run this step in nearly every single thing you do.

```{r load-tidyverse, exercise=TRUE}
library(tidyverse)
library(lubridate)
```
```{r load-tidyverse-solution}
library(tidyverse)
library(lubridate)
```
```{r load-tidyverse-check}
grade_this_code()
```
Now import the data.

```{r smells-load-data, message=FALSE, warning=FALSE}
crimes <- read_csv("http://mattwaite.github.io/datajournalismfiles/crimelogs.csv")
```
```{r smells-load-data-exercise, exercise = TRUE}
crimes <- read_csv("http://mattwaite.github.io/datajournalismfiles/crimelogs.csv")
```
```{r smells-load-data-exercise-solution}
crimes <- read_csv("http://mattwaite.github.io/datajournalismfiles/crimelogs.csv")
```
```{r smells-load-data-exercise-check}
grade_this_code()
```

## Wrong Type

First, let's look at **Wrong Type Of Data**. We can sniff that out by looking at the output of `glimpse`

### Exercise 1: Using glimpse for more than column names

```{r glimpse-data, exercise=TRUE, exercise.setup = "smells-load-data"}
glimpse(____)
```
```{r glimpse-data-solution, exercise.reveal_solution = FALSE}
glimpse(crimes)
```
```{r glimpse-data-check}
grade_this_code()
```

First things first: What type of data are all of the columns being imported as? An incident code is obviously text. But what about a case number? What about the dates? Are those character fields?

Bit of a trick question -- if you're not going to do math on it, don't import it as a number. Dates we've dealt with before. But just know, when you use `readr`, it's making guesses based on the first few rows. Sometimes, you'll get data that's a mix -- ID numbers that start as numbers and include text later. 

The cheap way to fix this is to change the guess_max parameter of `readr` to just use more than a few rows to guess the column types. It'll go a little slower, but often it fix the problem of mixed data types. For example, this would include the first 5,000 rows in the guessing.

```
crimes <- read_csv("http://mattwaite.github.io/datajournalismfiles/crimelogs.csv", guess_max = 5000)
```

## Missing Data

The second smell we can find in code is **missing data**. We can do that through a series of Group By and Count steps. In aggregates, we explicitly used group by and summarize. Here, because this is exploratory, I'm going to show you a shortcut called `tally()`. Tally ... does just that: tallies up how many are in your groups.

Let's first look at locations.

### Exercise 2: Missing data part 1

```{r tally-data, exercise=TRUE, exercise.setup = "smells-load-data"}
crimes |> 
  group_by(____) |> 
  ____()
```
```{r tally-data-solution, exercise.reveal_solution = FALSE}
crimes |> 
  group_by(location) |> 
  tally()
```
```{r tally-data-check}
grade_this_code()
```
What we're looking for here are blanks: Crimes without a location. Typically, those will appear first or last, depending on several things, so it's worth checking the front and back of our data. We can do that using reverse alphabetical order on our location. 

### Exercise 3: Missing data part 2
```{r tally2-data, exercise=TRUE, exercise.setup = "smells-load-data"}
crimes |> 
  group_by(____) |> 
  ____() |>
  arrange(desc(____))
```
```{r tally2-data-solution, exercise.reveal_solution = FALSE}
crimes |> 
  group_by(location) |> 
  tally() |>
  arrange(desc(location))
```
```{r tally2-data-check}
grade_this_code()
```

So far so good. We don't have any reported crimes without a location -- though recall from aggregates that the most common location for a crime was the police department.

What about crime type?

### Exercise 4: Missing data part 3

```{r tally3-data, exercise=TRUE, exercise.setup = "smells-load-data"}
crimes |> 
  group_by(_________) |> 
  ____()
```
```{r tally3-data-solution, exercise.reveal_solution = FALSE}
crimes |> 
  group_by(incident_code) |> 
  tally()
```
```{r tally3-data-check}
grade_this_code()
```

And now looking at it the other way.

```{r tally4-data, exercise=TRUE, exercise.setup = "smells-load-data"}
crimes |> 
  group_by(_________) |> 
  ____() |>
  arrange(desc(_________))
```
```{r tally4-data-solution, exercise.reveal_solution = FALSE}
crimes |> 
  group_by(incident_code) |> 
  tally() |>
  arrange(desc(incident_code))
```
```{r tally4-data-check}
grade_this_code()
```

None here either, so that's good. It means our incidents will always have a location and a type.

## Gaps in data

Let's now look at **gaps in data**. It's been my experience that gaps in data often have to do with time, so let's first look at incident dates, so we can see if there's any big jumps in data. You'd expect the numbers to change, but not by huge amounts. Huge change would indicate, more often than not, that the data is missing. Let's start with Date. If we're going to work with dates, we should have `lubridate` handy for `floor_date`.

### Exercise 5: Gaps

```{r gap-data, exercise=TRUE, exercise.setup = "smells-load-data"}
crimes |> 
  group_by(floor_date((mdy_hm(____)), "month")) |> 
  tally()
```
```{r gap-data-solution, exercise.reveal_solution = FALSE}
crimes |> 
  group_by(floor_date((mdy_hm(reported)), "month")) |> 
  tally()
```
```{r gap-data-check}
grade_this_code()
```

First thing to notice: our data has only 55 incidents in Janauary of 2018. That's because, if you were to look, it's only a partial month. Can that explain the small numbers in June and July? In this case no -- students have gone home. There's less for campus police to do. What about January 2023? Same story -- partial month. So can we include those months in any analysis? No we can't.

## Internal inconsistency

Any time you are going to focus on something, you should check it for consistency inside the data set. So let's pretend you want to look at *where* the most incidents occur on campus. To do this, you will need internally consistent addresses. Do you have that? 

### Exercise 6: Are they the same?

```{r consistent-data, exercise=TRUE, exercise.setup = "smells-load-data"}
crimes |> 
  group_by(____) |> 
  ____()
```
```{r consistent-data-solution, exercise.reveal_solution = FALSE}
crimes |> 
  group_by(location) |> 
  tally()
```
```{r consistent-data-check}
grade_this_code()
```

Look at the first 10 rows of data here. Do you notice anything? For data to be exact, each row must be the same. Are the same addresses here *itentical to each other?* Or do you see the same address inconsistently reported?

Can you accurately report on the number of indicents at each address with data like that? Not yet you can (more on that soon!).

And that's what Data Smells are designed to do: stop you from going down a bad path.
