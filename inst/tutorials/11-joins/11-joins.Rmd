---
title: "Data Journalism Lesson 11: Combining and joining"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
    theme: journal
    ace_theme: github
runtime: shiny_prerendered
description: >
  Joining two datasets together.
---
```{r setup, include=FALSE}
library(learnr)
library(gradethis)
library(tidyverse)
library(janitor)
library(glue)
knitr::opts_chunk$set(echo = FALSE)
tutorial_options(exercise.completion=FALSE)
```

## The Goal

In this lesson, you'll learn how to combine and join datasets, a crucial skill for data journalists. By the end of this tutorial, you'll understand how to use bind_rows() to stack datasets with identical structures, and how to use different types of joins (inner_join, left_join, right_join) to merge datasets based on common elements. You'll practice these techniques using real-world examples, such as merging monthly car sales tax data and combining train accident data with state information. These skills will enable you to work with more complex datasets and uncover deeper insights in your data journalism projects.

## The Basics

Often, as data journalists, we're looking at data across time or at data stored in multiple tables. And to do that, we often need to merge that data together. 

Depending on what we have, we may just need to stack data on top of each other to make new data. If we have 2019 data and 2018 data and we want that to be one file, we *bind* them. If we have a dataset of cows in counties and a dataset of populations in counties, we're going to *join* those two together on the county -- the common element.  

Let's explore.

## Combining data

Earlier in this class, we worked with data on car sales taxes. What you got was a nicely formatted dataset. That's not how it arrived. The state provides the data in monthly spreadsheets. To make those spreadsheets usable takes some editing in Excel.

But let's say you've done that and you have a monthly spreadsheet for both October and November, the two most recent months available as of this writing. How can you combine them into one?

Let's do what we need to import them properly. 

First we'll start with libraries. We'll need the tidyverse and janitor.

```{r load-tidyverse, exercise=TRUE}
library(tidyverse)
library(janitor)
```
```{r load-tidyverse-solution}
library(tidyverse)
library(janitor)
```
```{r load-tidyverse-check}
grade_this_code()
```

We're going to load two datasets in -- the first one is the October numbers and the second is the November numbers. But the names of the columns are all wrong for working in R, so we're going to use `clean_names` from janitor immediately after. 

```{r merge-load-data, message=FALSE, warning=FALSE}
october <- read_csv("http://mattwaite.github.io/datajournalismfiles/OctMV2023.csv") |> clean_names() |> remove_empty(which=c("cols", "rows"))

november <- read_csv("http://mattwaite.github.io/datajournalismfiles/NovMV2023.csv") |> clean_names() |> remove_empty(which=c("cols", "rows"))

october <- october |> 
  mutate(
    Month = as.Date("2023-10-01")
    )

november <- november |> 
  mutate(
    Month = as.Date("2023-11-01")
    )
```
```{r merge-load-data-exercise, exercise = TRUE}
october <- read_csv("http://mattwaite.github.io/datajournalismfiles/OctMV2023.csv") |> 
  clean_names() |>
  remove_empty(which=c("cols", "rows"))

november <- read_csv("http://mattwaite.github.io/datajournalismfiles/NovMV2023.csv") |> 
  clean_names() |> 
  remove_empty(which=c("cols", "rows"))
```
```{r merge-load-data-exercise-solution}
october <- read_csv("http://mattwaite.github.io/datajournalismfiles/OctMV2023.csv") |> 
  clean_names() |> 
  remove_empty(which=c("cols", "rows"))

november <- read_csv("http://mattwaite.github.io/datajournalismfiles/NovMV2023.csv") |> 
  clean_names() |> 
  remove_empty(which=c("cols", "rows"))
```
```{r merge-load-data-exercise-check}
grade_this_code()
```

Both of these datasets have the same number of columns, all with the same names, so if we want to merge them together to compare them over time, we need to stack them together. The verb here, in `dplyr`, is `bind_rows`. The good news about `bind_rows` is that it is very simple.

### Exercise 1: making a month

The problem we have first? Neither dataset has any information about what month it comes from. We have to add it with mutate. Here, we're going to add a Month column and populate it with the correct month in a date in case we need to do date math later. 

```{r add-month, exercise=TRUE, exercise.setup = "merge-load-data"}
october <- october |> 
  mutate(
    ____ = as.Date("2023-____-01")
    )

november <- november |> 
  mutate(
    ____ = as.Date("2023-____-01")
    )
```
```{r add-month-solution, exercise.reveal_solution = FALSE}
october <- october |> 
  mutate(
    Month = as.Date("2023-10-01")
    )

november <- november |> 
  mutate(
    Month = as.Date("2023-11-01")
    )
```
```{r add-month-check}
grade_this_code()
```

Now we're ready to bind rows. 

### Exercise 2: binding rows

It's very simple -- you just put the names of your dataframes into bind_rows. Here we're just going to bind them, but normally you'd add it to a new dataframe like this: `taxes <- bind_rows...`

```{r bind, exercise=TRUE, exercise.setup = "merge-load-data"}
bind_rows(____, ____)
```
```{r bind-solution, exercise.reveal_solution = FALSE}
bind_rows(october, november)
```
```{r bind-check}
grade_this_code()
```

And boom, like that, we have merged our two dataframes together. 

## Joining data

More difficult is when you have two separate tables that are connected by a common element or elements. 

Last year, there's was lot of interest in train derailments because of a disaster in East Palestine, Ohio. Let's load a dataset of train accidents from 2023 and figure out what states have the most train derailments in it. 

First, we'll load the data we need. The train derailment data stores states as FIPS codes, which is a federal numbering system for states and counties (and other geographies). So we're going to load that too while we're at it. 

```{r join-load-data, message=FALSE, warning=FALSE}
accidents <- read_csv("http://mattwaite.github.io/datajournalismfiles/trainaccidents2023.csv")

fips <- read_csv("http://mattwaite.github.io/datajournalismfiles/fips.csv")

accidentswithstates <- accidents |> inner_join(fips, by=c("STATE" = "FIPS"))
```
```{r join-load-data-exercise, exercise = TRUE}
accidents <- read_csv("http://mattwaite.github.io/datajournalismfiles/trainaccidents2023.csv")

fips <- read_csv("http://mattwaite.github.io/datajournalismfiles/fips.csv")
```
```{r join-load-data-exercise-solution}
accidents <- read_csv("http://mattwaite.github.io/datajournalismfiles/trainaccidents2023.csv")

fips <- read_csv("http://mattwaite.github.io/datajournalismfiles/fips.csv")
```
```{r join-load-data-exercise-check}
grade_this_code()
```

The trick to joining data is finding the columns that are the common element. Let's look at the accidents data first and find the column that would contain the state in it.

```{r accidents-head-data, exercise=TRUE, exercise.setup = "join-load-data"}
head(accidents)
```
```{r accidents-head-data-solution, exercise.reveal_solution = FALSE}
head(accidents)
```
```{r accidents-head-data-check}
grade_this_code()
```

Scroll to the right and it should be pretty obvious. The column is STATE. 

Now, the FIPS data.

```{r fips-head-data, exercise=TRUE, exercise.setup = "join-load-data"}
head(fips)
```
```{r fips-head-data-solution, exercise.reveal_solution = FALSE}
head(fips)
```
```{r fips-head-data-check}
grade_this_code()
```

This data is much smaller, but the column that contains what looks like the code that matches our STATE column in the accidents data is FIPS.

And now, we've arrived at the point where we can join the data. The problem we now face is what *kind* of join do we want to do? There's multiple kinds. The three we'll talk about here are the `left_join`, the `right_join` and the `inner_join`. 

The best way to think about this is to think of your data as two sheets of paper -- the accidents sheet is on the left, the fips sheet is on the right. A `left_join` would take all data from the accidents sheet and keep *only* the data that matched from the right sheet. The `right_join` is the opposite -- all fips data is kept, and only the matching accidents data is kept.

The `inner_join` keeps only the data where both match. In my career, the inner join is the one I've used the most. If a train accident happened somewhere that wasn't a state, do we want to know about it? And, often, looking at the results of that inner join are interesting -- how many accidents are put somewhere that isn't a valid FIPS code? So `inner_join` it is. 

The next issue is the column names are not the same. Joining in dplyr is easiest when the column names you want to join are the same. Alas, we aren't so lucky. So we have to specify which field equals which. And the order matters. 

### Exercise 3: joining

So we're going to put accidents on the left -- that would be the first position -- and fips on the right. Our accidents data has STATE and our fips data has FIPS, so the left side goes first and the right side goes second. 

```{r join1, exercise=TRUE, exercise.setup = "join-load-data"}
accidents |>
  inner_join(fips, by=c("____" = "____"))
```
```{r join1-solution, exercise.reveal_solution = FALSE}
accidents |>
  inner_join(fips, by=c("STATE" = "FIPS"))
```
```{r join1-check}
grade_this_code()
```

If you click the right arrow enough, you'll come to the FIPS data in there. So columns like State and Postal get added to the very end. 

But that means we can now get actual state names in our data in a group by and tally. So let's do that. Behind the scenes, I've created a dataframe called `accidentswithstates` that is the result of the join you did above.

```{r join-head-data, exercise=TRUE, exercise.setup = "join-load-data"}
head(accidentswithstates)
```
```{r join-head-data-solution, exercise.reveal_solution = FALSE}
head(accidentswithstates)
```
```{r join-head-data-check}
grade_this_code()
```


### Exercise 4: using our joined data

Let's filter so we only have derailments, which is Type 01, group by the new state name column and tally. **Watch that capitalization.** The STATE column that used to be in our accident data has been replaced with the State column from our FIPS data. 

```{r join2, exercise=TRUE, exercise.setup = "join-load-data"}
accidentswithstates |>
  filter(TYPE == "____") |>
  group_by(____) |>
  tally(sort=TRUE)
```
```{r join2-solution, exercise.reveal_solution = FALSE}
accidentswithstates |>
  filter(TYPE == "01") |>
  group_by(State) |>
  tally(sort=TRUE)
```
```{r join2-check}
grade_this_code()
```

And now you have the start of a story about Nebraska and train derailments. 

## The Recap

Throughout this lesson, you've learned two important techniques for working with multiple datasets: binding and joining. You've practiced using bind_rows() to combine datasets with identical structures, such as monthly car sales tax data. You've also explored different types of joins, focusing on inner_join() to merge train accident data with state information. Remember, choosing the right type of join is crucial for maintaining data integrity and getting accurate results. As you continue your data journalism journey, these skills will allow you to work with more diverse and complex datasets, enabling you to tell more comprehensive and insightful stories.

## Terms to Know

- `bind_rows()`: A dplyr function used to stack datasets with identical structures vertically.
- `inner_join()`: A type of join that keeps only the data where both datasets have matching values in the specified columns.
- `left_join()`: A join that keeps all data from the left dataset and only matching data from the right dataset.
- `right_join()`: A join that keeps all data from the right dataset and only matching data from the left dataset.
- `clean_names()`: A function from the janitor package that standardizes column names for easier data manipulation.
- `remove_empty()`: A janitor function that removes empty rows or columns from a dataset.
- `as.Date()`: A function used to convert strings or numbers into proper date objects in R.
- Common element: A column or set of columns that exist in both datasets and are used to match records when joining.
